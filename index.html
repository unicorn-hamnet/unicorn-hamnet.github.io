<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Modular architecture for non-prehensile manipulation.">
  <meta name="keywords" content="Non-prehensile, Modular">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HAMNET</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  
  <style>
    /* Math notation styling for closer sup/sub positioning like LaTeX */
    .math-notation {
      display: inline;
      white-space: nowrap;
    }
    
    .math-notation sup {
      font-size: 0.75em;
      vertical-align: super;
      line-height: 0;
    }
    
    .math-notation sub {
      font-size: 0.75em;
      vertical-align: sub;
      line-height: 0;
      margin-left: -0.1em;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- 
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yycho0108.github.io/research">Yoonyoung Cho*</a>,</span>
            <span class="author-block">
              <a href="https://junhyekh.github.io/">Junhyek Han*</a>,</span>
            <span class="author-block">
              <a href="https://jisuhann.github.io/">Jisu Han</a>,</span>
            <span class="author-block">
            <a href="https://beomjoonkim.github.io/">Beomjoon Kim</a></span>
          </div>
          <div class="is-size-5 publication-authors">
          <span class="author-block">KAIST</span>,
          <span class="author-block">*Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/pdf/paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.arxiv.org/abs/2502.20843"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/iMSquared/HAMNet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data (TBD)</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/video-cat.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">HAMNET</span> generalize across environments with diverse geometries.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/suitcase_throat_candy.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/tight_ceiling_bulldozer.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/grill_dino.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/big_basket_bulldozer.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/drawer_sanrio.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/circular_bin_pineapple.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/flat_nutella.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/big_basket_lemona.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/grill_bulldozer.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline style="width: 100%; height: 400px; object-fit: cover;">
            <source src="./static/videos/tight_ceiling_lemona.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            For robots to operate in general environments like households, they must be able to perform non-prehensile manipulation actions such as toppling and rolling to manipulate ungraspable objects. 
            However, prior works on non-prehensile manipulation cannot yet generalize across environments with diverse geometries. 
            The main challenge lies in adapting to varying environmental constraints: within a cabinet, the robot must avoid walls and ceilings; to lift objects to the top of a step, the robot must account for the step's pose and extent.
            While deep reinforcement learning (RL) has demonstrated impressive success in non-prehensile manipulation, accounting for such variability presents a challenge for the generalist policy, as it must learn diverse strategies for each new combination of constraints. 
            To address this, we propose a modular and reconfigurable architecture that adaptively reconfigures network modules based on task requirements. 
            To capture the geometric variability in environments, we extend the contact-based object representation (CORN) to environment geometries, and propose a procedural algorithm for generating diverse environments to train our agent. 
            Taken together, the resulting policy can zero-shot transfer to novel real-world environments and objects despite training entirely within a simulator.
            We additionally release a simulation-based benchmark featuring nine digital twins of real-world scenes with 353 objects to facilitate non-prehensile manipulation research in realistic domains.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section" id="Method">
  <div class="container is-max-desktop content">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
      </div>
    </div>

    <!-- Overall -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/overall_method_v7.png" alt="Overall Method" style="width: 70%; max-width: 600px;">
      <div class="content has-text-justified">
        <p>
          Our framework consists of four main components: a modular policy trained with RL, contact-based representation pre-training, a procedural domain generation scheme for environment geometries, and a simulation-to-real transfer method for real-world deployment.
        </p>
      </div>
    </div>
    </div>

    <div style="margin: 3rem 0;"></div>

    <!-- HAMNET Subsection -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4"><b><u>H</u></b>ierarchical <b><u>A</u></b>nd <b><u>M</u></b>odular <b><u>Net</u></b>work (HAMNET)</h3>
        <img src="./static/images/overall_arch.png" alt="Overall architecture">
        <div class="content has-text-justified">
          <p>
            Our model comprises three components – the geometry encoder (red), the modulation network
            (green), and the base network (blue). The geometry encoder embeds the point clouds, and the modulation network maps the
            embeddings and non-geometric state inputs to the base network's parameters θ. Conditioned on θ, the base network maps the
            state inputs and object geometry to actions and values. Input groups tagged with different numbers ( (1), (2), and (3)) indicate
            sets of non-geometric state inputs fed into different network parts. The inputs to cross-attention layers are concatenated and
            tokenized by a two-layer multi-layer perceptron (MLP).
          </p>
        </div>
      </div>
    </div>

    <div style="margin: 3rem 0;"></div>

    <!-- UniCORN Subsection -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4"><b><u>Uni</u></b>versal <b><u>C</u></b>ontact-based <b><u>O</u></b>bject <b><u>R</u></b>epresentation for <b><u>N</u></b>onprehensile Manipulation (UniCORN)</h3>
        <img src="./static/images/unicorn.png" alt="UniCORN architecture" style="width: 70%; max-width: 600px;">
        <div class="content has-text-justified">
          <p> 
            <b>FIXME: still awful spacing between superscript and subscript</b>
            Our pre-training architecture consists of a geometry encoder (red) and a contact decoder (green). 
            The same geometry encoder operates on each point cloud A and B in a Siamese fashion to produce local patch embeddings <span class="math-notation">z<sup>A</sup><sub>1:N-1</sub></span>, <span class="math-notation">z<sup>B</sup><sub>1:N-1</sub></span> 
             and global embeddings <span class="math-notation">z<sup>A</sup><sub>N</sub></span>, <span class="math-notation">z<sup>B</sup><sub>N</sub></span>. The contact decoder (green) predicts contact between each patch <span class="math-notation">z<sup>A</sup><sub>i</sub></span> ∈<span class="math-notation">z<sup>A</sup><sub>1:N-1</sub></span> and <span class="math-notation">z<sup>B</sup><sub>N</sub></span>. 
            The bottom block details the procedure to patchify and tokenize point clouds.
          </p>
        </div>
      </div>
    </div>
  </div>
  <div style="margin: 3rem 0;"></div>
  <!-- Proceudral generation of environments -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h3 class="title is-4">Procedural Domain Generation</h3>
      <video autoplay muted loop playsinline style="width: 40%; object-fit: cover;">
        <source src="./static/videos/seq-env-gen-v3.mp4" type="video/mp4">
      </video>
      <div class="content has-text-justified">
        <p>
          We propose a procedural algorithm for generating diverse environments to train our agent.
        </p>
      </div>
    </div>
  </div>


</section>

<section class="section" id="Emergent Skill Discovery">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Emergent Skill Discovery</h2>
      <div class="content has-text-justified">
        <p>
          TODO
        </p>
      </div>
    </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template borrowed from <a
            href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>

